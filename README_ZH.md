<div align= "center">
    <h1> ğŸ› ï¸ToolBenchğŸ¤–</h1>
</div>

<div align="center">

![Dialogues](https://img.shields.io/badge/Tool\_Num-3451-red?style=flat-square)
![Dialogues](https://img.shields.io/badge/API\_Num-16464-red?style=flat-square)
![Dialogues](https://img.shields.io/badge/Current\_Dataset\_Size-12K-red?style=flat-square)
![Dialogues](https://img.shields.io/badge/Total\_API\_Call-37K-red?style=flat-square)
![Dialogues](https://img.shields.io/badge/Average\_Reasoning\_Traces-4.1-red?style=flat-square)
![Dialogues](https://img.shields.io/badge/Tool\_LLaMA-Released-green?style=flat-square)

</div>

<p align="center">
  <a href="#model">Model</a> â€¢
  <a href="#data">Data Release</a> â€¢
  <a href="#web-ui">Web Demo</a> â€¢
  <a href="#tool-eval">Tool Eval</a> â€¢
  <a href="assets/paper.pdf">Paper</a> â€¢
  <a href="#citation">Citation</a>

</p>

</div>

<div align="center">
<img src="https://cdn.discordapp.com/attachments/941582479117127680/1111543600879259749/20230526075532.png" width="350px">
</div>

ğŸ”¨è¿™ä¸ªé¡¹ç›®(ToolLLM)æ—¨åœ¨æ„å»º**å¼€æºã€å¤§è§„æ¨¡ã€é«˜è´¨é‡**çš„æŒ‡ä»¤è°ƒæ•´ SFT æ•°æ®ï¼Œä»¥ä¿ƒè¿›æ„å»ºå…·æœ‰é€šç”¨å·¥å…·ä½¿ç”¨èƒ½åŠ›çš„å¼ºå¤§LLMsã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯èµ‹äºˆå¼€æº LLMs æŒæ¡æˆåƒä¸Šä¸‡å¤šæ ·çš„çœŸå®ä¸–ç•ŒAPIèƒ½åŠ›ã€‚æˆ‘ä»¬é€šè¿‡æ”¶é›†é«˜è´¨é‡çš„æŒ‡ä»¤è°ƒæ•´æ•°æ®é›†æ¥å®ç°è¿™ä¸€ç›®æ ‡ã€‚è¯¥æ•°æ®é›†ä½¿ç”¨æœ€æ–°çš„ChatGPTï¼ˆgpt-3.5-turbo-16kï¼‰è‡ªåŠ¨æ„å»ºï¼Œè¯¥ç‰ˆæœ¬å‡çº§äº†å¢å¼ºçš„å‡½æ•°è°ƒç”¨åŠŸèƒ½ã€‚æˆ‘ä»¬æä¾›æ•°æ®é›†ã€ç›¸åº”çš„è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬ï¼Œä»¥åŠåœ¨ToolBenchä¸Šç»è¿‡å¾®è°ƒçš„å¼ºå¤§æ¨¡å‹ToolLLaMAã€‚

**ğŸ’â€â™‚ï¸ğŸ’ğŸ’â€â™€ï¸åœ¨ [Discord](https://discord.gg/asjtEkAA) åŠ å…¥æˆ‘ä»¬!**

*è‹±æ–‡[README](README.md)é“¾æ¥.*

## æœ€æ–°æ”¯æŒ

- **[2023/8/4]** æˆ‘ä»¬æä¾›RapidAPIåç«¯æœåŠ¡ï¼Œä»¥å…æ‚¨ä½¿ç”¨è‡ªå·±çš„RapidAPIç§é’¥å»è®¢é˜…APIã€‚å¡«å†™[è¡¨å•](https://forms.gle/oCHHc8DQzhGfiT9r6)åï¼Œæˆ‘ä»¬ä¼šå°½å¿«å®¡æ ¸å¹¶ç»™æ‚¨å‘é€ToolBench keyå»è¯·æ±‚è¯¥åç«¯æœåŠ¡! 

- **[2023/8/1]** æˆ‘ä»¬çš„[è®ºæ–‡](https://arxiv.org/abs/2307.16789)æ­£å¼å‘å¸ƒ.

- **[2023/7/27]** æ–°ç‰ˆæœ¬ToolBenchæ›´æ–°.

âœ¨ä»¥ä¸‹æ˜¯æ•°æ®é›†æ„å»ºæ–¹æ³•ã€æ¨¡å‹è®­ç»ƒã€è¯„æµ‹çš„æ•´ä½“æ¦‚è§ˆ

<br>
<div align="center">
<img src="assets/overview.png" width="800px">
</div>
<br>

âœ¨âœ¨ç‰¹ç‚¹:
 - APIæ”¶é›†: æˆ‘ä»¬ä» RapidAPI æ”¶é›†äº† 16464 ä¸ªAPIã€‚RapidAPI æ˜¯ä¸€ä¸ªæ‰˜ç®¡å¼€å‘è€…æä¾›çš„å¤§è§„æ¨¡çœŸå®ä¸–ç•ŒAPIçš„å¹³å°ã€‚

 - æŒ‡ä»¤ç”Ÿæˆ: æˆ‘ä»¬ç”Ÿæˆäº†æ¶‰åŠå•å·¥å…·å’Œå¤šå·¥å…·åœºæ™¯çš„æŒ‡ä»¤ã€‚

 - ç­”æ¡ˆæ ‡æ³¨: æˆ‘ä»¬è®¾è®¡äº†ä¸€ç§æ–°é¢–çš„æ·±åº¦ä¼˜å…ˆæœç´¢å†³ç­–æ ‘æ–¹æ³•ï¼ˆDFSDTï¼‰ï¼Œä»¥å¢å¼ºLLMsçš„è§„åˆ’å’Œæ¨ç†èƒ½åŠ›ã€‚è¿™æ˜¾è‘—æé«˜äº†æ ‡æ³¨æ•ˆç‡ï¼Œå¹¶æˆåŠŸåœ°å¯¹é‚£äº›ä¸èƒ½ç”¨CoTæˆ–ReACTå›ç­”çš„å¤æ‚æŒ‡ä»¤è¿›è¡Œäº†æ ‡æ³¨ã€‚æˆ‘ä»¬æä¾›çš„å›ç­”ä¸ä»…åŒ…æ‹¬æœ€ç»ˆç­”æ¡ˆï¼Œè¿˜åŒ…æ‹¬æ¨¡å‹çš„æ¨ç†è¿‡ç¨‹ã€å·¥å…·æ‰§è¡Œå’Œå·¥å…·æ‰§è¡Œç»“æœã€‚

 - API Retriever: æˆ‘ä»¬æ•´åˆäº†APIæ£€ç´¢æ¨¡å—ï¼Œä¸ºToolLLaMAæä¾›äº†å¼€æ”¾åŸŸçš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚

 - æ‰€æœ‰æ•°æ®å‡ç”±OpenAI APIè‡ªåŠ¨ç”Ÿæˆå¹¶ç”±æˆ‘ä»¬ç­›é€‰ï¼Œæ•´ä¸ªæ•°æ®åˆ›å»ºè¿‡ç¨‹æ˜“äºæ‰©å±•ã€‚

<br>
<div align="center">
<img src="assets/comparison.png" width="800px">
</div>
<br>

ä»¥ä¸‹æ˜¯**ToolLLaMAçš„demoå±•ç¤º**

<div align="center">

https://github.com/OpenBMB/ToolBench/assets/25274507/f1151d85-747b-4fac-92ff-6c790d8d9a31

</div>

ç›®å‰ï¼Œæˆ‘ä»¬çš„ToolLLaMAå·²ç»è¾¾åˆ°äº†å’ŒChatGPTï¼ˆturbo-16kï¼‰æ¥è¿‘çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼Œæœªæ¥*æˆ‘ä»¬å°†ä¸æ–­è¿›è¡Œæ•°æ®çš„åå¤„ç†ä¸æ¸…æ´—ï¼Œä»¥æé«˜æ•°æ®è´¨é‡å¹¶å¢åŠ çœŸå®ä¸–ç•Œå·¥å…·çš„è¦†ç›–èŒƒå›´ã€‚*

<div align="center">
<img src="assets/performance.png" width="300px">
</div>

è¿™æ˜¯*[è€ç‰ˆæœ¬](https://github.com/OpenBMB/ToolBench/tree/legacy)*çš„ToolBenchã€‚
<!-- ğŸ’â€â™‚ï¸ğŸ’ğŸ’â€â™€ï¸**We need your help!** Curating large-scale real-world APIs and their corresponding tool-use SFT data is not easy, we sincerely invite you to join us in building and refining ToolBench. We will list all participants as co-authors in the final paper. Please contact and join [us](mailto:yujiaqin16@gmail.com) if you're interested. -->

## ğŸ—’ï¸æ•°æ®

ğŸ‘ToolBenchä»…ç”¨äºç ”ç©¶å’Œæ•™è‚²ç›®çš„ï¼Œä¸åº”è¢«è§†ä¸ºåæ˜ æ­¤æ•°æ®é›†çš„åˆ›ä½œè€…ã€æ‰€æœ‰è€…æˆ–è´¡çŒ®è€…çš„è§‚ç‚¹æˆ–æ„è§ã€‚è¯¥æ•°æ®é›†ä»¥ CC BY NC 4.0è®¸å¯è¯ è¿›è¡Œåˆ†å‘ã€‚ä»¥ä¸‹æ˜¯æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯:

| å·¥å…·æ•°é‡ | APIæ•°é‡ | å®ä¾‹æ•°é‡ | çœŸå®APIè°ƒç”¨æ•°é‡ | å¹³å‡Reasoningæ­¥æ•° |
|-----------|----------|---------------|---------------|------------------|
| 3451      | 16464    | 12657         | 37204         | 4.1              |

æˆ‘ä»¬ä»[RapidAPI](https://rapidapi.com/hub)çˆ¬å–äº†è¶…è¿‡16000ä¸ªAPIï¼Œå¹¶ä¸”ä¸ºä¹‹æ„é€ äº†çœŸå®çš„äººç±»æŒ‡ä»¤ã€‚ä»¥ä¸‹æ˜¯RapidAPIçš„æ¶æ„ä¿¡æ¯ä¸æŒ‡ä»¤æ„é€ çš„æ–¹å¼ã€‚

<br>
<div align="center">
<img src="assets/instructiongeneration.png" width="800px">
</div>
<br>


ToolBenchåŒ…å«å•å·¥å…·å’Œå¤šå·¥å…·åœºæ™¯ã€‚å¤šå·¥å…·åœºæ™¯å¯ä»¥è¿›ä¸€æ­¥åˆ†ä¸ºç±»åˆ«å†…å¤šå·¥å…·å’Œé›†åˆå†…å¤šå·¥å…·ã€‚æˆ‘ä»¬åœ¨æ•°æ®åˆ›å»ºè¿‡ç¨‹ä¸­ä½¿ç”¨DFSDTæ–¹æ³•ã€‚ä»¥ä¸‹æ˜¯ä½¿ç”¨DFSDTæ–¹æ³•è¿›è¡Œæ•°æ®åˆ›å»ºçš„è¯´æ˜ï¼š

<div align="center">

<img src="assets/answer_anno.png" width="800px">

</div>

### æ•°æ®å‘å¸ƒ

 è¯·ä½¿ç”¨ä»¥ä¸‹é“¾æ¥ä¸‹è½½æˆ‘ä»¬çš„æ•°æ®é›†ï¼š[Google Drive](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J)æˆ–è€…[æ¸…åäº‘ç›˜](https://cloud.tsinghua.edu.cn/f/c9e50625743b40bfbe10/).

 - `G1`ï¼Œ`G2`ï¼Œ`G3` æ•°æ®åˆ†åˆ«ä»£è¡¨å•å·¥å…·æ•°æ®ï¼Œç±»åˆ«å†…å¤šå·¥å…·æ•°æ®å’Œé›†åˆå†…å¤šå·¥å…·æ•°æ®ã€‚æˆ‘ä»¬åœ¨ G1ã€G2 å’Œ G3 æ•°æ®å†…åˆ†åˆ«åˆ’åˆ†å‡ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ï¼Œå¹¶å°†è®­ç»ƒé›†åˆå¹¶ï¼Œä½œä¸ºæˆ‘ä»¬çš„ä¸»è¦å®éªŒçš„è®­ç»ƒæ•°æ®ã€‚`toolllama_G123_dfs_train.json` æ–‡ä»¶ä»£è¡¨åˆå¹¶åçš„è®­ç»ƒé›†æ•°æ®ã€‚åŒæ—¶æˆ‘ä»¬ä¹Ÿç»™å‡ºäº†åŸºäºAtlasçš„æ•°æ®å¯è§†åŒ–ç»“æœï¼š[Atlas Explorer](https://atlas.nomic.ai/map/58aca169-c29a-447a-8f01-0d418fc4d341/030ddad7-5305-461c-ba86-27e1ca79d899) for visualizationã€‚
 - ä¸å·¥å…·ç¯å¢ƒç›¸å…³çš„æ•°æ®ä½äº `toolenv` ç›®å½•ä¸‹ã€‚
 - æˆ‘ä»¬ä»æ¯ä¸ªæµ‹è¯•é›†ä¸­æŠ½æ · 100 ä¸ªå®ä¾‹ã€‚`test_query_ids` ç›®å½•åŒ…å«æ¯ä¸ªæµ‹è¯•é›†ä¸­æµ‹è¯•å®ä¾‹çš„query idã€‚
 - ç”¨äºå·¥å…·æ£€ç´¢çš„æ•°æ®ä¹ŸåŒ…å«åœ¨ `retrieval` ç›®å½•ä¸­ã€‚


## ğŸ¤–æ¨¡å‹
æˆ‘ä»¬å‘å¸ƒäº†å…¨å‚æ•°å¾®è°ƒç‰ˆæœ¬[ToolLLaMA-7b](https://huggingface.co/ToolBench/ToolLLaMA-7b)å’Œloraç‰ˆæœ¬[ToolLLaMA-7b-LoRA](https://huggingface.co/ToolBench/ToolLLaMA-7b-LoRA)ï¼Œéƒ½æ˜¯åœ¨å‘å¸ƒçš„æ•°æ®é›†ä¸Šä»¥å¤šä»»åŠ¡æ–¹å¼è®­ç»ƒçš„ã€‚æˆ‘ä»¬ä¹Ÿå‘å¸ƒåœ¨å®éªŒè®¾ç½®ä¸‹è®­ç»ƒçš„[tool retriever](https://huggingface.co/ToolBench/ToolBench_IR_bert_based_uncased).
## ğŸš€ç²¾è°ƒ
### å®‰è£…
å…‹éš†è¿™ä¸ªä»“åº“å¹¶è¿›å…¥ToolBenchæ–‡ä»¶å¤¹ã€‚
```bash
git clone git@github.com:OpenBMB/ToolBench.git
cd ToolBench
```
å®‰è£…åŒ… (python>=3.9)
```bash
pip install -r requirements.txt
```
æˆ–è€…ä»…å®‰è£…ToolEvaléœ€è¦çš„åŒ…
```bash
pip install -r toolbench/tooleval/requirements.txt
```

å‡†å¤‡æ•°æ®å’Œå·¥å…·ç¯å¢ƒ:
```bash
wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1Vis-RxBstXLKC1W1agIQUJNuumPJrrw0&confirm=yes' -O data.zip
unzip data.zip
```


### è®­ç»ƒRetriever
- æ•°æ®é¢„å¤„ç†:
```bash
export PYTHONPATH=./
python data/preprocess_retriever_data.py \
    --query_file data/instruction/G1_query.json \
    --index_file data/test_query_ids/G1_instruction_test_query_ids.json \
    --dataset_name G1 \
    --output_dir data/retrieval/G1
```
- ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è®­ç»ƒRetriever:
```bash
export PYTHONPATH=./
python toolbench/retrieval/train.py \
    --data_path data/retrieval/G1/ \
    --model_name bert-base-uncased \
    --output_path retrieval_model \
    --num_epochs 5 \
    --train_batch_size 32 \
    --learning_rate 2e-5 \
    --warmup_steps 500 \
    --max_seq_length 256
```

### è®­ç»ƒToolLLaMA
æˆ‘ä»¬çš„è®­ç»ƒä»£ç åŸºäº[FastChat](https://github.com/lm-sys/FastChat)å¼€å‘.æ‚¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨ä¸¤å¼ A100ï¼ˆ80Gï¼‰è®­ç»ƒToolLLaMA-7b, è®­ç»ƒæ•°æ®æ˜¯æˆ‘ä»¬å·²ç»å¤„ç†å¥½çš„[æ•°æ®](https://drive.google.com/drive/folders/1yBUQ732mPu-KclJnuQELEhtKakdXFc3J):
```bash
export PYTHONPATH=./
torchrun --nproc_per_node=2 --master_port=20001 toolbench/train/train_long_seq.py \
    --model_name_or_path huggyllama/llama-7b  \
    --data_path  data/toolllama_G123_dfs_train.json \
    --eval_data_path  data/toolllama_G123_dfs_eval.json \
    --conv_template tool-llama-single-round \
    --bf16 True \
    --output_dir toolllama \
    --num_train_epochs 2 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 8 \
    --evaluation_strategy "epoch" \
    --prediction_loss_only \
    --save_strategy "epoch" \
    --save_total_limit 8 \
    --learning_rate 5e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.04 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --fsdp "full_shard auto_wrap" \
    --fsdp_transformer_layer_cls_to_wrap 'LlamaDecoderLayer' \
    --tf32 True \
    --model_max_length 8192 \
    --gradient_checkpointing True \
    --lazy_preprocess True \
    --report_to none
```

æ‚¨ä¹Ÿå¯ä»¥ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨æ‚¨è‡ªå·±çš„æ–¹å¼å»é¢„å¤„ç†å¹¶åˆ’åˆ†æ•°æ®:
```bash
export PYTHONPATH=./
python preprocess/preprocess_toolllama_data.py \
    --tool_data_dir data/answer/G1_answer \
    --method DFS_woFilter_w2 \
    --output_file data/answer/toolllama_G1_dfs.json
```


è®­ç»ƒloraç‰ˆæœ¬:
```bash
export PYTHONPATH=./
deepspeed --master_port=20001 toolbench/train/train_long_seq_lora.py \
    --model_name_or_path huggyllama/llama-7b  \
    --data_path  data/toolllama_G123_dfs_train.json \
    --eval_data_path  data/toolllama_G123_dfs_eval.json \
    --conv_template tool-llama-single-round \
    --bf16 True \
    --output_dir toolllama_lora \
    --num_train_epochs 5 \
    --per_device_train_batch_size 4 \
    --per_device_eval_batch_size 2 \
    --gradient_accumulation_steps 2 \
    --evaluation_strategy "epoch" \
    --prediction_loss_only \
    --save_strategy "epoch" \
    --save_total_limit 8 \
    --learning_rate 5e-5 \
    --weight_decay 0. \
    --warmup_ratio 0.04 \
    --lr_scheduler_type "cosine" \
    --logging_steps 1 \
    --model_max_length 8192 \
    --gradient_checkpointing True \
    --lazy_preprocess True \    
    --deepspeed ds_configs/stage2.json \
    --report_to none
```


## ç”¨æˆ‘ä»¬çš„RapidAPIæœåŠ¡è¿›è¡Œæ¨ç†
è¯·å…ˆå¡«å†™[é—®å·](https://forms.gle/oCHHc8DQzhGfiT9r6)ï¼Œæˆ‘ä»¬ä¼šå°½å¿«å®¡æ ¸ç„¶åç»™æ‚¨å‘é€toolbench keyã€‚ç„¶ååˆå§‹åŒ–æ‚¨çš„toolbench key:
```bash
export TOOLBENCH_KEY="your_toolbench_key"
```
### ToolLLaMA
ç”¨ä»¥ä¸‹å‘½ä»¤ç”¨ToolLLaMAåšæ¨ç†:
```bash
export PYTHONPATH=./
python toolbench/inference/qa_pipeline.py \
    --tool_root_dir data/toolenv/tools/ \
    --backbone_model toolllama \
    --model_path /path/to/your/toolllama \
    --max_observation_length 1024 \
    --observ_compress_method truncate \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo.json \
    --output_answer_file data/answer/toolllama_dfs \
    --toolbench_key $TOOLBENCH_KEY
```

**lora**ç‰ˆæœ¬çš„inference:
```bash
export PYTHONPATH=./
python toolbench/inference/qa_pipeline.py \
    --tool_root_dir data/toolenv/tools/ \
    --backbone_model toolllama \
    --model_path huggyllama/llama-7b \
    --lora \
    --lora_path /path/to/your/toolllama_lora \
    --max_observation_length 1024 \
    --observ_compress_method truncate \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo.json \
    --output_answer_file data/answer/toolllama_lora_dfs \
    --toolbench_key $TOOLBENCH_KEY
```

loraç‰ˆæœ¬çš„**å¼€æ”¾åŸŸ**, ç”¨ä»¥ä¸‹å‘½ä»¤:
```bash
export PYTHONPATH=./
python toolbench/inference/qa_pipeline_open_domain.py \
    --tool_root_dir data/toolenv/tools/ \
    --corpus_tsv_path data/retrieval/G1/corpus.tsv \
    --retrieval_model_path /path/to/your/retrival_model \
    --retrieved_api_nums 5 \
    --backbone_model toolllama \
    --model_path huggyllama/llama-7b \
    --lora \
    --lora_path /path/to/your/toolllama_lora \
    --max_observation_length 1024 \
    --observ_compress_method truncate \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo_open_domain.json \
    --output_answer_file data/answer/toolllama_lora_dfs_open_domain \
    --toolbench_key $TOOLBENCH_KEY
```
### OpenAIæ¨¡å‹
ç”¨ChatGPT:
```bash
export TOOLBENCH_KEY=""
export OPENAI_KEY=""
export PYTHONPATH=./
python toolbench/inference/qa_pipeline.py \
    --tool_root_dir data/toolenv/tools/ \
    --backbone_model chatgpt_function \
    --openai_key $OPENAI_KEY \
    --max_observation_length 1024 \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo.json \
    --output_answer_file data/answer/chatgpt_dfs \
    --toolbench_key $TOOLBENCH_KEY
```

ç”¨Text-Davinci-003:
```bash
export TOOLBENCH_KEY=""
export OPENAI_KEY=""
export PYTHONPATH=./
python toolbench/inference/qa_pipeline.py \
    --tool_root_dir data/toolenv/tools/ \
    --backbone_model davinci \
    --openai_key $OPENAI_KEY \
    --max_observation_length 1024 \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo.json \
    --output_answer_file data/answer/davinci_dfs \
    --toolbench_key $TOOLBENCH_KEY
```

## ç”¨æ‚¨è‡ªå·±çš„RapidAPIè´¦å·åšæ¨ç†
è¦ç”¨å®šåˆ¶åŒ–çš„RapidAPIè´¦å·è¿›è¡Œæ¨ç†ï¼Œè¯·åœ¨è„šæœ¬ä¸­ä¼ å…¥æ‚¨çš„**rapidapi key**å¹¶æŒ‡å®š`use_rapidapi_key`å‚æ•°:
```bash
export RAPIDAPI_KEY=""
export OPENAI_KEY=""
export PYTHONPATH=./
python toolbench/inference/qa_pipeline.py \
    --tool_root_dir data/toolenv/tools/ \
    --backbone_model chatgpt_function \
    --openai_key $OPENAI_KEY \
    --max_observation_length 1024 \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo.json \
    --output_answer_file data/answer/chatgpt_dfs \
    --rapidapi_key $RAPIDAPI_KEY \
    --use_rapidapi_key
```

## Setting up and running the interface

ToolBenchåŒ…å«ä¸€ä¸ªåŸºäº[Chatbot UI](https://github.com/mckaywrigley/chatbot-ui)çš„Web UIï¼Œç»è¿‡ä¿®æ”¹ä»¥åŒ…å«åœ¨ç•Œé¢ä¸­ä½¿ç”¨å·¥å…·çš„åŠŸèƒ½ã€‚å®ƒåŒ…å«ä¸¤ä¸ªéƒ¨åˆ†ï¼šåç«¯æœåŠ¡å™¨å’Œ[chatbot-ui-toolllama](https://github.com/lilbillybiscuit/chatbot-ui-toolllama)ã€‚è¿™æ˜¯ä¸€ä¸ª[è§†é¢‘æ¼”ç¤º](assets/toolbench-demo.mp4)ã€‚

### Web UI
```bash
git clone https://github.com/lilbillybiscuit/chatbot-ui-toolllama
cd chatbot-ui-toolllama
npm install
npm run dev
```

åº”ç”¨å°†åœ¨ http://localhost:3000/ ä¸Šå¯ç”¨

### Backend server
```bash
export PYTHONPATH=./
python toolbench/inference/toolbench_server.py \
    --tool_root_dir data/toolenv/tools/ \
    --corpus_tsv_path data/retrieval/G1/corpus.tsv \
    --retrieval_model_path /path/to/your/retrival_model \
    --retrieved_api_nums 5 \
    --backbone_model toolllama \
    --model_path huggyllama/llama-7b \
    --lora \
    --lora_path /path/to/your/toolllama_lora \
    --max_observation_length 1024 \
    --method DFS_woFilter_w2 \
    --input_query_file data/instruction/inference_query_demo_open_domain.json \
    --output_answer_file data/answer/toolllama_lora_dfs_open_domain \
    --rapidapi_key $RAPIDAPIKEY
```

This server will be available on `http://localhost:5000/`. To start a request, call `http://localhost:5000/stream` with a GET or POST request containing a JSON object with the following fields:
```json
{
    "text": "What is the weather in New York today?",
    "top_k": 5,
    "method": "DFS_woFilter_w2"
}
```


## ToolEval

é€šè¿‡åœ¨ToolBenchä¸Šå¯¹LLaMAè¿›è¡Œå¾®è°ƒï¼Œæˆ‘ä»¬å¾—åˆ°äº†**ToolLLaMA**ã€‚è€ƒè™‘åˆ°äººå·¥è¯„ä¼°éå¸¸è€—æ—¶ï¼Œæˆ‘ä»¬å€Ÿé‰´[AlpacaEval](https://tatsu-lab.github.io/alpaca_eval/)å¼€å‘äº†ä¸€ä¸ªé«˜æ•ˆçš„æœºå™¨è‡ªåŠ¨è¯„ä¼°**ToolEval**ï¼Œå…¶ä¸­åŒ…å«ä¸¤ä¸ªè¯„ä¼°æŒ‡æ ‡ï¼š

- **é€šè¿‡ç‡**ï¼šè®¡ç®—åœ¨æœ‰é™çš„OpenAI APIè°ƒç”¨æ¬¡æ•°å†…æˆåŠŸå®ŒæˆæŒ‡ä»¤çš„æ¯”ä¾‹ã€‚

- **åå¥½**ï¼šé€šè¿‡æ¯”è¾ƒç»™å®šæŒ‡ä»¤çš„ä¸¤ä¸ªç­”æ¡ˆï¼ˆåŠ¨ä½œåºåˆ—ï¼‰æ¥è¡¡é‡ã€‚æˆ‘ä»¬é¢„å…ˆå®šä¹‰äº†ä¸€ç»„æ›´å¥½ç­”æ¡ˆçš„æ ‡å‡†ï¼Œè¿™äº›æ ‡å‡†è¢«ç»„ç»‡æˆChatGPTçš„æç¤ºã€‚æˆ‘ä»¬å‘è¯„ä¼°å™¨æä¾›æµ‹è¯•æŒ‡ä»¤å’Œä¸¤ä¸ªå€™é€‰ç­”æ¡ˆï¼Œå¹¶è·å¾—å…¶åå¥½ã€‚æˆ‘ä»¬å¯¹æ¯ä¸ªç­”æ¡ˆå¯¹è¿›è¡Œå¤šæ¬¡è¯„ä¼°ä»¥æé«˜ç³»ç»Ÿçš„å¯é æ€§ã€‚ç„¶åï¼Œæˆ‘ä»¬è®¡ç®—**ä¼˜èƒœç‡**ï¼ˆè¢«è¯„ä¼°å™¨é€‰æ‹©ä¸ºæ›´ä¼˜çš„ç™¾åˆ†æ¯”ï¼‰å’Œ**æ ‡å‡†å·®**ï¼ˆä¼˜èƒœç‡çš„æ ‡å‡†è¯¯å·®ï¼‰ã€‚æœ‰å…³è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è®ºæ–‡ã€‚

ä¸ºäº†éªŒè¯åå¥½æŒ‡æ ‡çš„æœ‰æ•ˆæ€§ï¼Œæˆ‘ä»¬ä»ä¸‰ç§ä¸åŒæ–¹æ³•ï¼ˆChatGPT+ReACTã€GPT4+ReACTå’ŒChatGPT+DFSDTï¼‰ä¸­éšæœºæŠ½æ ·è·å¾—600ä¸ªæµ‹è¯•æŒ‡ä»¤çš„ç­”æ¡ˆå¯¹ã€‚ç„¶åï¼Œæˆ‘ä»¬é‚€è¯·äººå·¥æ ‡æ³¨äººå‘˜å¯¹å®ƒä»¬è¿›è¡Œäººå·¥åå¥½æ³¨é‡Šï¼ˆæ¯ä¸ªç­”æ¡ˆå¯¹4ä¸ªæ³¨é‡Šï¼Œæ€»å…±2400ä¸ªæ³¨é‡Šï¼‰ã€‚æˆ‘ä»¬ä½¿ç”¨ChatGPTå¼€å‘çš„è‡ªåŠ¨è¯„ä¼°å™¨ä¸äººå·¥æ ‡æ³¨è€…å‘ˆç°å‡ºæ˜¾è‘—çš„**75.8%**ç›¸å…³æ€§ã€‚æˆ‘ä»¬è¿˜è·å¾—äº†ä¸åŒäººå·¥æ ‡æ³¨è€…ä¹‹é—´çš„ä¸€è‡´æ€§ä¸º**83.54%**ï¼Œä¸æˆ‘ä»¬çš„è¯„ä¼°å™¨å’Œäººç±»æ ‡æ³¨è€…ä¹‹é—´çš„ä¸€è‡´æ€§ä¸º**80.21%**ã€‚

æœ‰å…³ToolEvalçš„æ›´å¤šç»†èŠ‚ï¼Œè¯·å‚é˜…æˆ‘ä»¬çš„è®ºæ–‡ã€‚


### Evaluation with ToolEval
è¦åœ¨æµ‹è¯•é›†ï¼ˆå¦‚G1-Inst.ï¼‰ä¸Šè¯„ä¼°æ¨¡å‹ï¼Œå¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
- é€šè¿‡ç‡:
```bash
python toolbench/tooleval/pass_rate.py --answer_dir data/answer/toolllama_dfs/G1_instruction
```
- ä¼˜èƒœç‡ (å‚è€ƒæ¨¡å‹: ChatGPT-ReACT):
```bash
export OPENAI_KEY=""
export REF_MODEL_DATA="data/answer/chatgpt_cot/G1_instruction"
export REF_MODEL_METHOD="CoT"
export TEST_MODEL_DATA="data/answer/toolllama_dfs/G1_instruction"
export TEST_MODEL_METHOD="DFS"
python ./toolbench/tooleval/convert_to_answer_format.py \
    --method CoT \
    --answer_dir $REF_MODEL_DATA \
    --output ${REF_MODEL_DATA}_converted

python ./toolbench/tooleval/convert_to_answer_format.py \
    --method DFS \
    --answer_dir $TEST_MODEL_DATA \
    --output ${TEST_MODEL_DATA}_converted

python ./toolbench/tooleval/automatic_eval_sample.py \
    --output ${REF_MODEL_DATA}_converted \
    --ref_output ${TEST_MODEL_DATA}_converted \
    --method $REF_MODEL_METHOD \
    --use_existed_output
```

### Model Experiment

åœ¨æˆ‘ä»¬çš„ä¸»è¦å®éªŒä¸­ï¼ŒToolLLaMAå±•ç°äº†å¤„ç†å•ä¸€å·¥å…·å’Œå¤æ‚å¤šå·¥å…·æŒ‡ä»¤çš„å¼•äººæ³¨ç›®çš„èƒ½åŠ›ã€‚
ä»¥ä¸‹æ˜¯ä¸ChatGPTå’ŒText-Davinci-003ç›¸æ¯”çš„ä¸»è¦ç»“æœã€‚

**é€šè¿‡ç‡**
| model                   | I1-Inst. | I1-Tool. | I1-Cat. | I2-Inst. | I2-Cat. | I3-Inst. | Average  |
|-------------------------|----------|----------|---------|----------|---------|----------|----------|
| ChatGPT-DFSDT           | **78**   | **84**   | **89**  | **51**   | **58**  | **57**   | **69.6** |
| ChatGPT-ReACT           | 56       | 62       | 66      | 28       | 22      | 30       | 44.0     |
| Text-Davinci-003-DFSDT  | 53       | 58       | 61      | 38       | 38      | 39       | 47.8     |
| Text-Davinci-003-ReACT  | 19       | 25       | 30      | 12       | 11      | 14       | 18.5     |
| ToolLLaMA               | 68       | 80       | 75      | 47       | 56      | 40       | 61.0     |
| ToolLLaMA-LoRA          | 51       | 63       | 61      | 38       | 42      | 45       | 50.0     |
| ToolLLaMA-API Retriever | 62       | 62       | 72      | 45       | 55      | 47       | 57.2     |

**ä¼˜èƒœç‡** (å‚è€ƒæ¨¡å‹: ChatGPT-DFSDT)
| model                  | I1-Inst. | I1-Tool. | I1-Cat. | I2-Inst. | I2-Cat. | I3-Inst. | Average |
|------------------------|----------|----------|---------|----------|---------|----------|---------|
| ChatGPT-DFSDT | 50       | 50       | 50      | 50       | 50      | 50       | 50.0    |
| ChatGPT-ReACT | 38       | 32       | 41      | 43       | 22      | 23       | 30.7    |
| Text-Davinci-003-ReACT | 14       | 21       | 18      | 8       | 7      | 12       | 13.3    |
| Text-Davinci-003-DFSDT | 38       | 34       | 43      | 25       | 20      | 28       | 31.3    |
| ToolLLaMA              | **50**       | 45       | 45      | **59**       | 48      | 46       | 48.8    |
| ToolLLaMA-LoRA              | 43       | 36.4       | 30      | 42       | 45      | **51**       | 41.2    |
| ToolLLaMA-API Retriever              | **51**       | 39       | 44      | 49       | 49      | **55**       | 47.8    |


## TODO
- [ ] ToolLLaMAå°†è¾¾åˆ°GPT-4çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚
- [ ] æˆ‘ä»¬å°†è®­ç»ƒä¸€ä¸ªToolLLaMa-2ã€‚

## å·¥å…·å­¦ä¹ ç›¸å…³é“¾æ¥

é‰´äºåŸºç¡€æ¨¡å‹çš„å¼ºå¤§èƒ½åŠ›ï¼Œæˆ‘ä»¬æœŸå¾…çœ‹åˆ°å®ƒä»¬åœ¨æ“çºµå„ç§å·¥å…·ä¸­çš„åº”ç”¨ã€‚æ›´å¤šçš„èµ„æºï¼Œè¯·å‚è€ƒä»¥ä¸‹å†…å®¹ï¼š

- **BMTools**. [[Project](https://github.com/OpenBMB/BMTools)]

- **Tool Learning Survey**. [[Paper](https://arxiv.org/abs/2304.08354)]
  
- **Tool Learning Paper List**. [[Project](https://github.com/thunlp/ToolLearningPapers)]

- **WebCPM**. [[Paper](https://github.com/thunlp/WebCPM)]

## Citation
å¦‚æœæ‚¨å¯¹ToolBenchæ„Ÿå…´è¶£ï¼Œæ¬¢è¿å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œã€‚

```bibtex
@misc{qin2023tool,
      title={Tool Learning with Foundation Models}, 
      author={Yujia Qin and Shengding Hu and Yankai Lin and Weize Chen and Ning Ding and Ganqu Cui and Zheni Zeng and Yufei Huang and Chaojun Xiao and Chi Han and Yi Ren Fung and Yusheng Su and Huadong Wang and Cheng Qian and Runchu Tian and Kunlun Zhu and Shihao Liang and Xingyu Shen and Bokai Xu and Zhen Zhang and Yining Ye and Bowen Li and Ziwei Tang and Jing Yi and Yuzhang Zhu and Zhenning Dai and Lan Yan and Xin Cong and Yaxi Lu and Weilin Zhao and Yuxiang Huang and Junxi Yan and Xu Han and Xian Sun and Dahai Li and Jason Phang and Cheng Yang and Tongshuang Wu and Heng Ji and Zhiyuan Liu and Maosong Sun},
      year={2023},
      eprint={2304.08354},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
